## a process is independent

- if it does not share data with any other processes

## a process is cooperating

- if it can affect or be affected by the other processes
- inter process communication
- cooperating processes require an IPC mechanism
    - that will allow them to exchange data
    - that is send data to and recieve data from each other

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c46eb2a2-bfe5-4c12-8b0d-a42648ac37b4/Untitled.png)

### IPC in shaerd-memory systems

- consider the producer-consumer problem

### producer comsumer problem

- a producer produces infro that is consumed by a consumer
- a compiler produces assembly code, and, assembler consumes it
- a web server produces an html file, and browser consumes it
- a solution using shared memory
    - to allow producer and consumer to run concurrently
    - let a buffer of items be available
        - a producer can fill the buffer and
        - a consumer can empty the buffer
- a shared memory
    - requires that these process share  a region of memory and that
    - the code for accessing and manipulating the shared memory
        - be written explictly by the application programmer
- message-passing
    - o/s provides the means for cooperating proceeses
    - message-passing facility
        - send
        - receive
- prosumer - prosumer
    - shaderd memory
    - message passing
        - os 시스템 콜에 감쳐지고
        - direct connection이 만들어고
        - if two processes P and Q want to communicate
        - sync async
        - automatic or explict

## IPC in direct communication
프로세스 간 통신

- shared memory
- message passing  (os가 해줘!)
- each processes that wants to communicate
- send(p, message)
- recieve(q, message)
- links are established automatically
- a link is associated with exactly two processes

### in direct

- the messages are sent to and recieved from mailbox or ports
- a mailbox(ports)
    - 메시지를 보내는 장소
    - 메시지를 받는 장소
- the primitives of this scheme
    - send(a, message)
    - receive(a, message)
- the properties of communication links
    - only if both members of the pair have a shared mailbox
- a link may be associated with more than two processes
- a number of links may exist
- os provides a mechanism that allows a processes to do:
    - create a new mailbox
    - send and receive message through the mailbox
    - delete a mailbox

### design options of implementation

- blocking send:

---

### Different design options for implementation

- different design options for implementation
    - blocking or non-blocking: sync or async
- blocking send: the sender is blocked until the message is recevied
- non-blocking: the sender is sends the message and continue
- blocking receive: the receiver blocks until a message is available
- non blokcing receive: the receiver receives either a valid message or a null message
- blocking: 어떤 작업이 완료될 때 까지 실행 흐름이 멈춰있는 상태
- non-blokcing: 실행 흐름이 해당 작업의 완료를 기다리지 않고 계속 진행되는 상태를 의미

---

## IPC 통신의 실제

### IPC system

### POSIX shared memory

- portable operating system interface (for unix)
    - 운영체제의 표준화 시도 했음
- is organized using memory-mapped files
    - memory-mapped file을 사용
        - 당연히 디스크 계열보다 빠르겠지?
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/61a2c55e-7dcd-410e-bfe7-c5446b792b8f/Untitled.png)
    
    - 4096 kb 청크
    - 메모리 매핑
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/3f878dd7-94a0-41d9-b769-8b4520c08463/Untitled.png)
    
- segmentation fault
    - 메모리에서 허용되지 않는 영역에 접근할 때 발생하는 에러
    - 이것은 프로그램의 불안정성을 나타내는 오류
    - 메모리 엑세스: 메모 내 특정 영역에만 액세스 가능
    - 포인터 잘못참조, 배열의 경계를 벗어나는 접근, 스택 오버플로우,  메모리의 해제 문제
    - stack overflow
        
        스택 오버플로우 공격은 프로그램의 취약점을 이용하여 실행 스택의 특정 영역을 의도적으로 넘쳐서 다른 데이터 또는 반환 주소를 덮어쓰는 해킹 기법 중 하나입니다. 이를 통해 공격자는 임의의 코드를 실행할 수 있게 되며, 시스템을 제어하거나 원치 않는 동작을 유발시키는 데 이용될 수 있습니다.
        
        스택 오버플로우 해킹 기법의 작동 원리는 다음과 같습니다:
        
        1. **스택 구조의 이해**: 기본적으로 스택은 지역 변수, 반환 주소, 파라미터 등을 저장하는 데 사용되는 후입선출 (LIFO) 데이터 구조입니다. 함수가 호출될 때, 반환 주소와 지역 변수들이 스택에 푸시(push)됩니다. 함수가 종료되면 이 정보는 팝(pop)되어 스택에서 제거됩니다.
        2. **버퍼 오버플로우**: 스택 오버플로우는 대개 버퍼 오버플로우의 한 형태로, 버퍼(즉, 배열 또는 문자열)에 너무 많은 데이터를 쓰는 것에서 발생합니다. 이로 인해 스택에 있는 다른 데이터, 특히 반환 주소를 덮어쓸 수 있습니다.
        3. **제어 흐름의 변경**: 공격자는 오버플로우를 사용하여 스택에 있는 반환 주소를 임의의 위치로 변경할 수 있습니다. 예를 들어, 공격자가 삽입한 악성 코드의 위치로 변경할 수 있습니다.
        4. **쉘코드 실행**: 공격자는 스택에 악성 코드(쉘코드)를 삽입하고 반환 주소를 이 코드의 위치로 설정하여 프로그램이 해당 코드를 실행하도록 만들 수 있습니다.
        5. **보호 메커니즘 우회**: 최신 운영 체제와 컴파일러는 스택 오버플로우 공격을 방지하기 위한 다양한 메커니즘을 제공합니다. 예를 들면, 스택 캔러리, NX(No Execute) 비트, ASLR(Address Space Layout Randomization) 등이 있습니다. 그러나 공격자들은 이러한 보호 메커니즘을 우회하는 방법을 찾아내곤 합니다.
        
        즉, 스택 오버플로우는 공격자가 시스템의 제어를 획득하기 위해 프로그램의 취약점을 악용하는 방법입니다. 이런 공격을 방지하기 위해 항상 안전한 프로그래밍 방법을 사용하고, 시스템 및 소프트웨어의 업데이트와 패치를 꾸준히 수행하는 것이 중요합니다.
        

### pipes

- one of the earliest IPC mechanisms on UNIX systems
- pipe(int fd[])
    - fd[0]  read_END
    - fd[1] write_END

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/a693f11b-6c06-429d-88ff-a47b59dd2e8a/Untitled.png)

## socket

- two other strategies in client-server system
- are defiend as endpoints for communication
- 특정 컴퓨터를 어떻게 특정?
    - ip address를 통해
- pipe를 어떻게 특정?
    - port
- ip address + port → 소켓
- 소켓은: 원격지간 커뮤니케이션을 위한 엔드포인트
    - 두 원격지간 32bit, 64bit 다르게 지원한다면?

### rpc

- remote procedue calls (원격 컴퓨터 콜)
- abstracts procedure calls between processes on networked systems

### in java

- socket: connection oriented (*tcp)
- datagramsocket: connectionless (*udp)
- multicastsocket: multiple recipients

---

## Thread & Concurrency

- so far was assumed that
- single thread of control
- a process is able to contain multiple threads of control
- a lightweight process (lpw)
- a basic unit of cpu utilization
- comprises a thread id, a program counter, a reigster set, and a stack

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/61aeb801-ccdd-46ba-be69-6d20ac0f8a84/Untitled.png)

- 멀티 프로세싱 ↔ 멀티 스레딩
- 멀티 스레딩 장점

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/5aa6e5fe-c747-4613-b3b3-d19f264d1d9f/Untitled.png)

- let us consider the case of client-server system
- responsivness: non-blocking으로 실행
- resource sharing: 중간에 shared-memory, message-passing을 사용하고 있었는데
thread는 code,data, heap 영역을 공유
- economy: cheaper than porcess creation
    - pcb 컨텍스트 스위칭 ↔ 스레드 스위칭
- scalability: process can take advantage of multiprocessor arch
- cf): 고루틴은 os 스레드보다 훨씬 작은 메모리 스택을 사용
    - 고루틴은 작은 스택으로 시작해서 필요에 따라 도동적으로 스택 크기를 확장, 축소
    - 스위칭 비용
    - 오버헤드 적음
    - 이 때 언급되는 os스레드는 커널 레벨

### in-java

- threads are the fundamental model of program execution

three techniques

- inheritance from the Thread class
- java는 다중상속이 안 됨
- Implementing Runnable interface
- Lambda expression

Multi threading in multicore system

- more efficient use of multiple cores for imporved concurrency
- consider an application with for threads
    - single-core: threads will be interleaved(시분할) over time
    - multiple-cores: some threads can run in parallel

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/95ee8c6a-6f1e-45a2-8fcf-45fd9fb10b0e/Untitled.png)

---

### programming challenge in multicore systems

- identifiying tasks: find areas can be divided into seperate tasks
    - parallel 하게 할 수있는 job가 없는 잡을 분리
- balance: ensure the tasks to perform equal work of equal value
- data splitting: data alos must be divided to run on seperate cores
- data dependency: ensure that the execution of tasks if sync to accomodate the data dependency
- testing and debugging: more difficult than single-thread

### type of parallesim:

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ca2906bd-d1b9-43e5-ac63-020e4888d5f6/Untitled.png)

- data ↔ task parallesim
- 요즘 세상은 distributed
    - 컴퓨터 자원이 엄청나기 때문에

Amdahl’s law

- 코어는 무조건 많을수록 좋은가
    - S: serial 하게 실행되어야 하는거
    - N: 프로세싱 코어
- 모든 job을 병렬적으로 돌릴 수 없음

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/1fa1fd5d-9401-4dd7-bb37-f3319e771bf6/Untitled.png)

---

## multi- threading

- two types of threads
    - user thread
    - kernel thread (*운영체제가 직접)
- in-java
    - concurrent하게 실행할 수 있다 뿐이지 코어를 마음대로 할 수 없음
    - green-thread → os thread

### user thread

- user space
- without kernel support

### kernel thread

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/657d1e43-4250-477a-b16c-7d158ec3cbf6/Untitled.png)

- three relationships between user and kernel threads
    - may-to-one
    - one-to-one
    - many-to-many

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/c52c9c1e-2d96-4d35-a795-c93ad58587da/Untitled.png)

---

### open mp

- a set of complier directives(지시어) and an API for programs written in c/c++
- parllel region as blocks of code
- insert compiler directives into source code at parallel
    - pragma
- implict(명시적인) ↔ explict(암묵적인)

---

### scheduling

- fcfs , sjf
    - first come first , shortest first job
    - sjf 스케쥴링은 provably optimal
        - minimum average waiting time
        - consequently the average waiting time decreases
    - can you implement the SJF scheduling?
        - optimal
        - there is no way to know the length of the next cpu burst
        - try to approximate(근사적) SJF scheduling
            - predict the length of the next cpu
            - pick a process with the shortest predicted cpu burst
        - how to predict next cpu burst?
            - exponential average of the measured lengths of previous
        - the sjf alogrithm can be either preemptive or non-preemptive
            - when a new process arrives at the ready queue
            - while a previous process is still executing
            - what if a newly arrived process is shorter than
                - what is left of the currently executing process?
            - SRTF scheduling
                - shortest-remaining-time-first: preemptive sjf scheduling
                - srtf will prompt the currently running process
                    - whereas a non-preemptive sjf will allow it to finish it’s cpu burst
    
    ### RR
    
    - time sharing할려면
    - cpu bursting
    - round-robin: preemptive fcfs with a time quantum
    - a time quantum is a small unit of time
        - generally from 10 to 100 milliseconds in length
        - the ready queue is treated as a circular queue
    - process may have a cpu brust of less than one time
        - 자발적으로 빠져나오는 상황
    - cpu burst is longer than one time
        - interrupt
        - → ready queue
    - rr scheduling algo is preemptive
    - time quantum 에 따라 성능이 달라짐
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8f53e3a9-5bb7-440b-8063-43a2f3435989/Untitled.png)
    
    ### priority-base scheduling
    
    - 우선순위를 어떻게 줄 거임?
        - a priority is associated with each process
    - preemptive ↔ non-preemptive
        - srtf ↔ sjf
    - the problem of starvation(indefinite blocking)
        - ready queue에 있는 낮은 우선순위를 가진 큐가 중간에 우선순위 높은 일들이 들어오면
        무한정으로 대기할 수 있음
    - a solution to the starvation problem is `aging`
        - 나이를 주자
    
    ### combine RR + priority
    
    - execute the highest-priority process
    - runs processes with the same prioirty using round-robin
    
    ### multi level queue
    
    - 안드로이드폰 게임하고 있음
        - 전화가 온다면(카톡)?
        - 게임에 필요한 사운드 디스플레이, 네트웤이 각 각 있을 때 동일한 priority를 갖고 있을까?
        - n개의 ready queue에 priority를 나누자
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/cd74ddf4-d28f-4c72-bb30-cde1b6e81ef6/Untitled.png)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6a0ce106-4104-4821-a3db-cd76b5b4b267/Untitled.png)
    
    ### multi-level feedback queue
    
    - 각 각 분리하다 보니 아래 레벨에 있는 큐들은 실행을 할 수 없음
    - 대부분 현대 OS 스케쥴링 알고리즘
    - RR → RR → FCFS
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/180916a5-9b65-413c-8dbd-e4932d4ddb2a/Untitled.png)
    
    ### on most modern operating systems
    
    - it is kernel threads - not processes
        - that are being scheduled
    - and user threads are managed by a thread library
        - so the kernel is unaware of them
        - ultimately mapped to associated kernel
    
    ### real time cpu scheduling
    
    - 실시간 OS란? → 주어진 시간 내에 어떤 task를 완료할 수 있어야함
    - soft realtime ↔ hard realtime
        - 얼추 맞춰야됨  ↔ 무조건!..(dead line)
        - 전화기 rfc 신호 ↔ 로켓
        - 우선순위 역전현상..?
        - 달 탐사 로켓 이야기
        

---

# 동기화

## 프로세스 동기화

- synchronization
- cooperating process
    - can either affect or be affected
    - share a logical address space or share date
- data inconsistency
    - orderly execution
    - maintain data consistency
- integrity of data
- concurrent, parallel
- 컨텍스트 스위칭이 발생할 수 있음
    
    ```go
    register = count
    register = register + 1
    count = register
    ```
    

instruction이 언제 일어날 지?

- even tho register1 and register2 may be the same physical register
    - the content of these register will be
    - saved and restored by interrupt handler(or scheduler)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/861f8ef0-a8ed-42c4-8792-8f7217235a6e/Untitled.png)

### race condition

- a situation
    - where several processes
    - access and manipulate the same or shared data concurrency
    - depends on the particular order
- only one process at a time
    - synchronize
    - data access를 순차적으로

## Critical Section Problem